{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNX650r7X9GwDoahN8BaUgM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimcaprio/lifeofkaggle/blob/master/Baseline_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wHJ6sFD2mls",
        "colab_type": "text"
      },
      "source": [
        "# Baseline 모델\n",
        "## tabular 데이터를 다루는 캐클의 파이프라인\n",
        "### 1. 데이터 전처리 -> 2. 피처엔지니어링 -> 3. 머신러닝 모델학습 -> 4. 테스트 데이터 예측 및 캐글 업로드\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwVGkqiC3Gb5",
        "colab_type": "text"
      },
      "source": [
        "1.   데이터 전처리\n",
        "\n",
        "*   제품 변수의 결측값을 0으로 대체. 제품 보유 여부에 대한 정보가 없으면, 해당 제품을 보유하지 않고 있지 않다고 가정.\n",
        "*   훈련 데이터와 테스트 데이터를 통합. 훈련 데이터와 테스트 데이터는 날짜변수(fecha_dato)로 쉽게 구분 가능. 동일한 24개의 고객 변수를 공유하고 있으며, 테스트 데이터에 없는 24개의 제품 변수는 0으로 채움.\n",
        "* 번주형, 수치형 데이터를 전처리. 변수형 데이터는 .factorize()통해 label encoding을 수행. 데이터 타입이 object로 표현되는 수치형 데이터에서는 .unique()를 통해 특이값들을 대체하거나 제거하고, 정수형 데이터로 변환.\n",
        "*   추후 모델 학습에 사용할 변수 이름을 features 리스트에 미리 담는다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuO1MEyA69ok",
        "colab_type": "code",
        "outputId": "c0351861-bb38-4f59-a28a-88389b83a985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lVUCwgC7TtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/My Drive/CoLab/explorer_of_machine_learning/for_kaggle/.kaggle/\" # put path for wherever you put it"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkCA9mkb2l_7",
        "colab_type": "code",
        "outputId": "ef64e780-7f0e-4b17-d86d-126a955cb970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "\n",
        "np.random.seed(2018)\n",
        "\n",
        "# 데이터를 불러온다\n",
        "trn = pd.read_csv('/content/drive/My Drive/CoLab/explorer_of_machine_learning/ch02_santander/data/train_ver2.csv')\n",
        "tst = pd.read_csv('/content/drive/My Drive/CoLab/explorer_of_machine_learning/ch02_santander/data/test_ver2.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (5,8,11,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76du4a0Aqohx",
        "colab_type": "code",
        "outputId": "f736bb59-dd14-4452-fcf9-438d55850b7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "## 데이터 전처리\n",
        "# 제품 변수를 별도로 저장\n",
        "prods = trn.columns[24:].tolist()\n",
        "\n",
        "# 제품 변수 결측값을 미리 0으로 대체\n",
        "trn[prods] = trn[prods].fillna(0.0).astype(np.int8)\n",
        "\n",
        "# 24개 제품 중 하나도 보유하지 않는 고객 데이터를 제거\n",
        "no_product = trn[prods].sum(axis=1) == 0\n",
        "trn = trn[~no_product]\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터를 통합. 테스트 데이터에 없는 제품 변수는 0으로 대체\n",
        "for col in trn.columns[24:]:\n",
        "  tst[col] = 0\n",
        "df = pd.concat([trn, tst], axis=0)\n",
        "\n",
        "# 학습에 사용할 변수를 담는 list\n",
        "features = []\n",
        "\n",
        "# 범주형 변수를 .factorize() 함수를 통해 label encoding 함(one-hot) -- 날짜 데이터는 제외 시켜야...\n",
        "# 그래서 모든 object type 변수를 fatorize 해서는 안됨... categorical_cols = [col for col in trn.columns[:24] if trn[col].dtype in ['O']]\n",
        "categorical_cols = ['ind_empleado', 'pais_residencia', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp','canal_entrada', 'indfall', 'tipodom', 'nomprov', 'segmento']\n",
        "\n",
        "for col in categorical_cols:\n",
        "  df[col], _ = df[col].factorize(na_sentinel=-99)\n",
        "features += categorical_cols\n",
        "\n",
        "# 수치형 변수의 특이값과 결측값을 -99로 대체하고, 정수형으로 변환\n",
        "df['age'].replace(' NA', -99, inplace=True)\n",
        "df['age'] = df['age'].astype(np.int8)\n",
        "\n",
        "df['antiguedad'].replace('     NA', -99, inplace=True)\n",
        "df['antiguedad'] = df['antiguedad'].astype(np.int8)\n",
        "\n",
        "df['renta'].replace('         NA', -99, inplace=True)\n",
        "df['renta'].fillna(-99, inplace=True)\n",
        "df['renta'] = df['renta'].astype(float).astype(np.int8)\n",
        "\n",
        "df['indrel_1mes'].replace('P', 5, inplace=True)\n",
        "df['indrel_1mes'].fillna(-99, inplace=True)\n",
        "df['indrel_1mes'] = df['indrel_1mes'].astype(float).astype(np.int8)\n",
        "\n",
        "#학습에 사용할 수치형 변수를 features에 추가\n",
        "#features +=  [col for col in trn.columns[:24] if trn[col].dtype in ['int64', 'float64']]\n",
        "features += ['age', 'antiguedad', 'renta', 'ind_nuevo', 'indrel', 'indrel_1mes', 'ind_actividad_cliente']\n",
        "print(features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ind_empleado', 'pais_residencia', 'sexo', 'tiprel_1mes', 'indresi', 'indext', 'conyuemp', 'canal_entrada', 'indfall', 'tipodom', 'nomprov', 'segmento', 'age', 'antiguedad', 'renta', 'ind_nuevo', 'indrel', 'indrel_1mes', 'ind_actividad_cliente']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0MeYTErP888",
        "colab_type": "text"
      },
      "source": [
        "2.   피처 엔지니어링\n",
        "*   모델 학습에 사용할 파생변수를 생성."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruovoQQ1eU5U",
        "colab_type": "code",
        "outputId": "1b6f3b1a-4acb-4b46-a785-6cb3cf9d3420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        }
      },
      "source": [
        "df['fecha_alta'].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2015-01-12\n",
              "1    2012-08-10\n",
              "2    2012-08-10\n",
              "3    2012-08-10\n",
              "4    2012-08-10\n",
              "Name: fecha_alta, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjZdfeboP8UX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (피처 엔지니어링) 두 날짜 변수에서 연도와 월 정보를 추출\n",
        "df['fecha_alta_month'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
        "df['fecha_alta_year'] = df['fecha_alta'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
        "features += ['fecha_alta_month', 'fecha_alta_year']\n",
        "\n",
        "df['ult_fec_cli_1t_month'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[1])).astype(np.int8)\n",
        "df['ult_fec_cli_1t_year'] = df['ult_fec_cli_1t'].map(lambda x: 0.0 if x.__class__ is float else float(x.split('-')[0])).astype(np.int16)\n",
        "features += ['ult_fec_cli_1t_month', 'ult_cli_1t_year']\n",
        "\n",
        "# 그 외 변수의 결측값은 모두 -99로 변환\n",
        "df.fillna(-99, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QR5zFM_XjM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (피처 엔지니어링) lag-1 데이터를 생성\n",
        "# # 날짜를 숫자로 변환하는 함수. 2015-01-28 은 1, 2016-06-28은 18로 변환\n",
        "def date_to_int(str_date):\n",
        "  Y, M, D = [int(a) for a in str_date.strip().split(\"-\")]\n",
        "  int_date = (int(Y) - 2015) * 12 + int(M)\n",
        "  return int_date\n",
        "\n",
        "# 날짜를 숫자로 변환하여 int_date에 저장\n",
        "df['int_date'] = df['fecha_dato'].map(date_to_int).astype(np.int8)\n",
        "\n",
        "# 데이터를 복사하고, int_date 날짜에 1을 더하여 lag를 생성. 변수명에 _prev를 추가\n",
        "df_lag = df.copy()\n",
        "df_lag.columns = [col + '_prev' if col not in ['ncodpers', 'int_date'] else col for col in df.columns]\n",
        "df_lag['int_date'] += 1\n",
        "\n",
        "# 원본 데이터와 lag 데이터를 ncodper와 int_date 기준으로 합침. lag 데이터의 int_date는 1이 밀려 있기 때문에, 저번 달의 제품 정보가 삽입.\n",
        "df_trn = df.merge(df_lag, on=['ncodpers', 'int_date'], how='left')\n",
        "\n",
        "# 메모리 효율을 위해 불필요한 변수르 메모리에서 제거.\n",
        "#del df, df_lag\n",
        "\n",
        "# 저번달의 제품 정보가 존재하지 않을 경우를 대비하여 0으로 대체\n",
        "for prod in prods:\n",
        "  prev = prod + '_prev'\n",
        "  df_trn[prev].fillna(0, inplace=True)\n",
        "df_trn.fillna(-99, inplace=True)\n",
        "\n",
        "# lag-1 변수를 추가\n",
        "features += [feature + '_prev' for feature in features]\n",
        "features += [prod + '_prev' for prod in prods]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ttt1nxKUZXlT",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "3.   교차검증\n",
        "\n",
        "\n",
        "*   테스트 데이터 제외하고 주어진 train 데이터를 활용하여 교차검증 데이터로 활용\n",
        "*   시계열 데이터의 경우, 테스트 데이터 중 마지막 날짜 또는 년, 월 을 교차검증 데이터로 분리하여 활용하는 것이 일반적. <- 미래를 예측하는 모델이기 때문\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQKAez1jaApF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 모델 학습\n",
        "# 학습을 위하여 데이터를 훈련, 테스트용으로 분리\n",
        "# 학습에는 2016-01-28 ~ 2016-04-28 epdlxjaks tkdyd, 검증에는 2016-05-28 epdlxjfmf tkdyd.\n",
        "use_dates = ['2016-01-28', '2016-02-28', '2016-03-28', '2016-04-28', '2016-05-28']\n",
        "trn = df_trn[df_trn['fecha_dato'].isin(use_dates)]\n",
        "tst = df_trn[df_trn['fecha_dato'] == '2016-06-28']\n",
        "#del df_trn\n",
        "\n",
        "print(\"tst\", tst)\n",
        "\n",
        "# 훈련 데이터에서 신규 구매 건수만 추출\n",
        "X = []\n",
        "Y = []\n",
        "for i, prod in enumerate(prods):\n",
        "  prev = prod + '_prev'\n",
        "  prX = trn[(trn[prod] == 1) & (trn[prev] == 0)]\n",
        "  prY = np.zeros(prX.shape[0], dtype=np.int8) + i\n",
        "  X.append(prX)\n",
        "  Y.append(prY)\n",
        "XY = pd.concat(X)\n",
        "Y = np.hstack(Y)\n",
        "XY['y'] = Y\n",
        "\n",
        "#훈련, 검증 데이터로 분리\n",
        "vld_date = '2016-05-28'\n",
        "XY_trn = XY[XY['fecha_dato'] != vld_date]\n",
        "XY_vld = XY[XY['fecha_dato'] == vld_date]\n",
        "\n",
        "print(\"XY_trn\", XY_trn)\n",
        "print(\"XY_vld\", XY_vld)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUToWvAJwBni",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   xgboost 모델을 사용 하여 학습 모델 만들기\n",
        "2.   주요 파라미터\n",
        "*   max_depth : 트리 모델의 최대 깊이를 의미. 값이 높을 수록 더 복잡한 트리를 만들지만, 과적합의 원인이 될수 있음.\n",
        "*   eta : 딥러닝에서의 learning rate 의미. 0과 1사이의 값을 가지며, 값이 너무 높으면 학습이 잘 안되고, 낮으면 학습에 시간이 오래 걸림.\n",
        "*   colsample_bytree : 트리를 생성할 때 룬련 데이터에서 변수를 샘플링해주는 비율. 마찬가지로 과적합을 막아주는 방안. (딥러닝의 drop out 개념?) 보통 0.6 ~ 0.9\n",
        "*   colsample_bylevel : 트리의 레벨 별로 훈련 데이터의 변수를 샘플링해주는 비율. 보통 0.6 ~ 0.9\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XWYHmwEwBBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## XGBoost 모델 parameter를 설정\n",
        "param = {\n",
        "  'booster': 'gbtree',\n",
        "  'max_depth' : 8,\n",
        "  'nthread' : 4,\n",
        "  'num_class' : len(prods),\n",
        "  'objective' : 'multi:softprob',\n",
        "  'silent' : 1,\n",
        "  'eval_metric' : 'mlogloss',\n",
        "  'eta' : 0.1,\n",
        "  'min_child_weight' : 10,\n",
        "  'colsample_bytree' : 0.8,\n",
        "  'colsample_bylevel' : 0.9,\n",
        "  'seed' : 2018,\n",
        "}\n",
        "\n",
        "# 훈련, 검증 데이터를 XGBoost 형태로 변환\n",
        "X_trn = XY_trn.as_matrix(columns=features)\n",
        "Y_trn = XY_trn.as_matrix(columns=['y'])\n",
        "dtrn = xgb.DMatrix(X_trn, label=Y_trn, feature_names=features)\n",
        "\n",
        "X_vld = XY_vld.as_matrix(columns=features)\n",
        "Y_vld = XY_vld.as_matrix(columns=['y'])\n",
        "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)\n",
        "\n",
        "print(Y_vld)\n",
        "\n",
        "# XBBoost 모델을 훈련 데이터로 학습\n",
        "watch_list = [(dtrn, 'train'), (dvld, 'eval')]\n",
        "model = xgb.train(param, dtrn, num_boost_round=1000, evals=watch_list, early_stopping_rounds=20)\n",
        "\n",
        "import pickle\n",
        "pickle.dump(model, open('/content/drive/My Drive/CoLab/explorer_of_machine_learning/ch02_santander/modle/xgb.baseline.pkl', 'wb'))\n",
        "best_ntree_limit = model.best_ntree_limit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG4v1Wv9AdDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def apk(actual, predicted, k=7, default=0.0):\n",
        "    if len(predicted) > k:\n",
        "        predicted = predicted[:k]\n",
        "    #MAP@7 이므로, 최대 7개만 사용\n",
        "\n",
        "    score = 0.0\n",
        "    num_hits = 0.0\n",
        "\n",
        "    for i , p in enumerate(predicted):\n",
        "        #점수를 부여하는 조건은 다음과 같음 :\n",
        "        # 예측 값이 정답에 있고 ('p in actual')\n",
        "        # 예측 값이 중복이 아니면('p not in predicted[:i]')\n",
        "        if p in actual and p not in predicted[:i]:\n",
        "            num_hits += 1.0\n",
        "            score += num_hits / (i+1.0)\n",
        "\n",
        "        #정답 값이 공백일 경우, 무조건 0.0을 반환\n",
        "    if not actual:\n",
        "      return default\n",
        "    # print(\"score / min(len(actual), k) :: \", score / min(len(actual), k))\n",
        "    #정답의 개수(len(actual))로 averate precision을 구한다\n",
        "    return score / min(len(actual), k)\n",
        "\n",
        "#list of list인 정답 값(actual)과 예측값(predicted)에서 고객별 Average Precision을 구하고, np.mean()을 통해 평균을 계산\n",
        "def mapk(actual, predicted, k=7, default=0.0):\n",
        "    # rst = [apk(a,p,k,default) for a,p in zip(actual, predicted)]\n",
        "    # print(\"rst ::: \", rst[:1000])\n",
        "    return np.mean([apk(a,p,k,default) for a,p in zip(actual, predicted)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd57-Yl_7Ae2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "5.   평가\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35tunzI47AA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MAP@7 평가 척도를 위한 준비작업.\n",
        "# 고객 식별 버놓를 추출한다.\n",
        "vld = trn[trn['fecha_dato'] == vld_date]\n",
        "ncodpers_vld = vld.as_matrix(columns=['ncodpers'])\n",
        "\n",
        "#print(\"ncodpers_vld : \", ncodpers_vld)\n",
        "#print(\"vld : \", vld)\n",
        "\n",
        "# 검증 데이터에서 신규 구매를 구한다\n",
        "for prod in prods:\n",
        "  prev = prod + '_prev'\n",
        "  padd = prod + '_add'\n",
        "\n",
        "  vld[prev] = vld[prev].astype(float).astype(np.int8)\n",
        "  vld[prod] = vld[prod].astype(float).astype(np.int8)\n",
        "\n",
        "  vld[padd] = vld[prod] - vld[prev]\n",
        "\n",
        "add_vld = vld.as_matrix(columns=[prod + '_add' for prod in prods])\n",
        "#ncodpers_vld 크기의 list를 생성\n",
        "add_vld_list = [list() for i in range(len(ncodpers_vld))]\n",
        "\n",
        "# 고객별 신규 구매 정답 값을 add_vld_list에 저장하고, 총 count를 count_vld에 저장한다.\n",
        "count_vld = 0\n",
        "for ncodper in range(len(ncodpers_vld)):\n",
        "    for prod in range(len(prods)):\n",
        "      if add_vld[ncodper, prod] > 0:\n",
        "        # print(\"ncodper : \", ncodper, \"  || prod : \", prod)\n",
        "        add_vld_list[ncodper].append(prod)\n",
        "        count_vld += 1\n",
        "        \n",
        "# print(\"count_vld : \", count_vld)\n",
        "# print(\"add_vld_list[0:10] : \", add_vld_list[0:1000])\n",
        "\n",
        "#import map7 as mapk\n",
        "# 고객 데이터에서 얻을 수 있는 MAP@7 최고점을 미리 구함.(0.042663)\n",
        "print(mapk(add_vld_list, add_vld_list, 7, 0.0))\n",
        "\n",
        "# 검증 데이터에 대한 예측값을 구한다\n",
        "X_vld = vld.as_matrix(columns=features)\n",
        "Y_vld = vld.as_matrix(columns=['y'])\n",
        "dvld = xgb.DMatrix(X_vld, label=Y_vld, feature_names=features)\n",
        "preds_vld = model.predict(dvld, ntree_limit=best_ntree_limit)\n",
        "\n",
        "# 저번 달에 보유한 제품은 신규 구매가 불가하기 때문에, 확률값에서 미리 1을 빼줌\n",
        "preds_vld = preds_vld - vld.as_matrix(columns=[prod + '_prev' for prod in prods])\n",
        "\n",
        "# 검증 데이터 예측 상위 7개를 추출\n",
        "result_vld = []\n",
        "for ncodper, pred in zip(ncodpers_vld, preds_vld):\n",
        "  y_prods = [(y,p,ip) for y, p, ip, in zip(pred, prods, range(len(prods)))]\n",
        "  y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
        "  result_vld.append([ip for y,p,ip in y_prods])\n",
        "\n",
        "# 검증 데이터에서의 MAP@7 점수를 구한다.\n",
        "print(mapk(add_vld_list, result_vld, 7, 0.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkKDPASSvHXw",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "5.   테스트 데이터 예측 및 캐글 업데이트\n",
        "\n",
        "\n",
        "*   XGBoost의 get_fscore() 함수를 통해서 학습한 모델의 변수 중요도를 출력 가능\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkrtp-4XvNvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# XGBoost 모델을 전체 훈련 데이터로 재학습한다!\n",
        "X_all = XY.as_matrix(columns=features)\n",
        "Y_all = XY.as_matrix(columns=['y'])\n",
        "dall = xgb.DMatrix(X_all, label=Y_all, feature_names=features)\n",
        "watch_list =[(dall, 'train')]\n",
        "\n",
        "# 트리 개수를 늘어난 데이터 양만큼 비례해서 증가\n",
        "best_ntree_limit = int(round(int(best_ntree_limit * (len(XY_trn) + len(XY_vld)))/(len(XY_trn))))\n",
        "# print(type(best_ntree_limit.astype(float8).astype(int8)))\n",
        "#XGBoost 모델 재 학습\n",
        "model = xgb.train(param, dall, num_boost_round=best_ntree_limit, evals=watch_list)\n",
        "\n",
        "#변수 중요도를 출력해본다. 예상하던 변수가 상위로 올라와 있는가?\n",
        "print(\"Feature importance:\")\n",
        "for kv in sorted([(k,v) for k, v in model.get_fscore().items()], key=lambda kv: kv[1], revers=True):\n",
        "  print(kv)\n",
        "\n",
        "# 캐글 제출을 위하여 테스트 데이터에 대한 예측값을 구함\n",
        "X_tst = tst.as_matrix(column=features)\n",
        "dtst = xgb.Dmatrix(X_tst, feature_names=features)\n",
        "preds_tst = model.predict(dtst, ntreelimit=best_ntree_limit)\n",
        "ncodpers_tst = tst.as_matrix(columns=['ncodpers'])\n",
        "pred_tst = preds_tst - tst.as_matrix(columns=[prod + '_prev' for prod in prods])\n",
        "\n",
        "#제출 파일을 생성\n",
        "submit_file = open(\"/content/drive/My Drive/CoLab/explorer_of_machine_learning/ch02_santander/modle/xgb.baseline.2020-02-05\", 'w')\n",
        "submit_file.write('ncodpers, added_products\\n')\n",
        "for ncodper, pred in zip(ncodpers_tst, preds_tst):\n",
        "  y_prods = [(y, p, ip) for y, p, ip in zip(pred, prods, range(len(prods)))]\n",
        "  y_prods = sorted(y_prods, key=lambda a: a[0], reverse=True)[:7]\n",
        "  submit_file.write('{},{}\\n'.format(int(nccoodper), ' '.join(y_prods)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JugKcQJ7lgqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}